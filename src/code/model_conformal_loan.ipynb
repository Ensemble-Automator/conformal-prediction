{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of this program is to perform a baseline analysis for conformal prediction on a simple ANN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split #don't use for time-series baseline!\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/loan/train.csv\")\n",
    "test_df = pd.read_csv(\"../../data/loan/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(dataframe, isTest=False):\n",
    "    \"\"\"Preprocess a dataframe, unique to the loan_prediction dataset\"\"\"\n",
    "    #perform deep copy, fixes self assignment bug:\n",
    "    #https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "    df = dataframe.copy(deep=True)\n",
    "    \n",
    "    null_df = np.sum(df.isnull())\n",
    "    print(null_df) \n",
    "    print(f\"\\nTotal null values: {np.sum(null_df)}\") #get total number of null values\n",
    "    ### remove all rows with null values\n",
    "    df = df.dropna(how='any',axis=0) \n",
    "    del df['Loan_ID'] #remove Loan_ID (irrelevant)\n",
    "\n",
    "    # convert to binary variables\n",
    "\n",
    "    ##----------------------------------------------------------------------------\n",
    "    #### ----------------------------------Table----------------------------------\n",
    "    ##----------------------------------------------------------------------------\n",
    "\n",
    "    #> ----Gender---\n",
    "    ## - Male: 0\n",
    "    ## - Female: 1\n",
    "    df.loc[(df.Gender == 'Male'),'Gender']=0\n",
    "    df.loc[(df.Gender == 'Female'),'Gender']=1\n",
    "\n",
    "    #> ----Married---\n",
    "    ## - No: 0\n",
    "    ## - Yes: 1\n",
    "    df.loc[(df.Married == 'Yes'),'Married']=0\n",
    "    df.loc[(df.Married == 'No'),'Married']=1\n",
    "\n",
    "    #> ----Education---\n",
    "    ## - Not Graduate: 0\n",
    "    ## - Graduate: 1\n",
    "    df.loc[(df.Education == 'Not Graduate'),'Education']=0\n",
    "    df.loc[(df.Education == 'Graduate'),'Education']=1\n",
    "\n",
    "    #> ----Self_Employed---\n",
    "    ## - No: 0\n",
    "    ## - Yes: 1\n",
    "    df.loc[(df.Self_Employed == 'No'),'Self_Employed']=0\n",
    "    df.loc[(df.Self_Employed == 'Yes'),'Self_Employed']=1\n",
    "\n",
    "\n",
    "    #> ----Property_area---\n",
    "    ## - Rural: 0\n",
    "    ## - Urban: 1\n",
    "    ## - Semiurban: 2\n",
    "    df.loc[(df.Property_Area == 'Rural'),'Property_Area']=0\n",
    "    df.loc[(df.Property_Area == 'Urban'),'Property_Area']=1\n",
    "    df.loc[(df.Property_Area == 'Semiurban'),'Property_Area']=2\n",
    "    \n",
    "    \n",
    "    #> ----Loan_Status--- (ONLY for Training set)\n",
    "    ## - No: 0\n",
    "    ## - Yes: 1\n",
    "    if(not isTest):\n",
    "        df.loc[(df.Loan_Status == 'N'),'Loan_Status']=0\n",
    "        df.loc[(df.Loan_Status == 'Y'),'Loan_Status']=1\n",
    "\n",
    "    #> -----Dependents-----\n",
    "    #set max as \n",
    "    df.loc[(df.Dependents == '3+'), 'Dependents'] = 3\n",
    "    ##----------------------------------------------------------------------------\n",
    "    #### ----------------------------------Table----------------------------------\n",
    "    ##----------------------------------------------------------------------------\n",
    "\n",
    "    #!!! Typecase to float (for tensors below)\n",
    "    df = df.astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n",
      "\n",
      "Total null values: 149\n",
      "Loan_ID               0\n",
      "Gender               11\n",
      "Married               0\n",
      "Dependents           10\n",
      "Education             0\n",
      "Self_Employed        23\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount            5\n",
      "Loan_Amount_Term      6\n",
      "Credit_History       29\n",
      "Property_Area         0\n",
      "dtype: int64\n",
      "\n",
      "Total null values: 84\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess_df(train_df)\n",
    "test_df = preprocess_df(test_df, isTest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5417.0</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "1     0.0      0.0         1.0        1.0            0.0           4583.0   \n",
       "2     0.0      0.0         0.0        1.0            1.0           3000.0   \n",
       "3     0.0      0.0         0.0        0.0            0.0           2583.0   \n",
       "4     0.0      1.0         0.0        1.0            0.0           6000.0   \n",
       "5     0.0      0.0         2.0        1.0            1.0           5417.0   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "1             1508.0       128.0             360.0             1.0   \n",
       "2                0.0        66.0             360.0             1.0   \n",
       "3             2358.0       120.0             360.0             1.0   \n",
       "4                0.0       141.0             360.0             1.0   \n",
       "5             4196.0       267.0             360.0             1.0   \n",
       "\n",
       "   Property_Area  Loan_Status  \n",
       "1            0.0          0.0  \n",
       "2            1.0          1.0  \n",
       "3            1.0          1.0  \n",
       "4            1.0          1.0  \n",
       "5            1.0          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head() #processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2165.0</td>\n",
       "      <td>3422.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0     0.0      0.0         0.0        1.0            0.0           5720.0   \n",
       "1     0.0      0.0         1.0        1.0            0.0           3076.0   \n",
       "2     0.0      0.0         2.0        1.0            0.0           5000.0   \n",
       "4     0.0      1.0         0.0        0.0            0.0           3276.0   \n",
       "5     0.0      0.0         0.0        0.0            1.0           2165.0   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                0.0       110.0             360.0             1.0   \n",
       "1             1500.0       126.0             360.0             1.0   \n",
       "2             1800.0       208.0             360.0             1.0   \n",
       "4                0.0        78.0             360.0             1.0   \n",
       "5             3422.0       152.0             360.0             1.0   \n",
       "\n",
       "   Property_Area  \n",
       "0            1.0  \n",
       "1            1.0  \n",
       "2            1.0  \n",
       "4            1.0  \n",
       "5            1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head() #processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "X = train_df.drop('Loan_Status',axis=1).values\n",
    "y = train_df['Loan_Status'].values\n",
    "\n",
    "# X_test = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data feature space: (480, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data feature space: {X.shape}\")\n",
    "# print(f\"Testing data feature space: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create tensors from np.ndarry main data\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #Enable cuda if available\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train = torch.FloatTensor(X_train).to(device)\n",
    "X_test = torch.FloatTensor(X_test).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main model for loan prediction (try out different values for hidden layers to improve baseline)\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_features=11, layer1=20, layer2=20, out_features=2):\n",
    "        \"\"\"Initialize the model for loan prediction\"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, layer1)\n",
    "        self.fc2 = nn.Linear(layer1, layer2)\n",
    "        self.out = nn.Linear(layer2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass with 11 input features\"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the model for reproducibility\n",
    "torch.manual_seed(0)\n",
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=11, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (out): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model ##describe model, sort of (integrate tensorboard into PyTorch, not now tho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement backprop\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005) #adam works well for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=int(1e3), print_every=100, epsilon=0.5):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    - assumes access to following global variables: X_train, y_train, y_pred, model, loss function, & optimizer.\n",
    "    @Param:\n",
    "    1. epochs - number of training iterations.\n",
    "    2. print_every - for visual purposes (set to None to ignore), outputs loss\n",
    "    3. epsilon - threshold to break training.\n",
    "    \"\"\"\n",
    "    start_time = time.time() #set start time\n",
    "    losses = [] #plot\n",
    "    \n",
    "    for i in range(1, epochs+1):\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_function(y_pred, y_train)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if(loss.item() <= epsilon):\n",
    "            print(f\"\\nCONVERGED at epoch {i} - loss : {loss.item()}\")\n",
    "            break #converged\n",
    "        \n",
    "        if(print_every is not None and i%print_every == 1):\n",
    "            print(f\"Epoch {i} - loss : {loss.item()}\")\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"total training time (sec):\", time.time()-start_time)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss : 61.35926818847656\n",
      "Epoch 101 - loss : 1.3116317987442017\n",
      "Epoch 201 - loss : 0.677432119846344\n",
      "Epoch 301 - loss : 0.9265301823616028\n",
      "Epoch 401 - loss : 0.6723325848579407\n",
      "Epoch 501 - loss : 0.6378673315048218\n",
      "Epoch 601 - loss : 0.6845365166664124\n",
      "Epoch 701 - loss : 0.5160427093505859\n",
      "Epoch 801 - loss : 0.5029237866401672\n",
      "Epoch 901 - loss : 0.49082985520362854\n",
      "Epoch 1001 - loss : 0.4796518385410309\n",
      "Epoch 1101 - loss : 0.4928981065750122\n",
      "Epoch 1201 - loss : 0.6383454203605652\n",
      "Epoch 1301 - loss : 0.4567399322986603\n",
      "Epoch 1401 - loss : 0.44539836049079895\n",
      "Epoch 1501 - loss : 0.44730091094970703\n",
      "Epoch 1601 - loss : 0.7375766634941101\n",
      "Epoch 1701 - loss : 0.4289802014827728\n",
      "Epoch 1801 - loss : 0.411828875541687\n",
      "Epoch 1901 - loss : 0.4025292694568634\n",
      "Epoch 2001 - loss : 0.651762068271637\n",
      "Epoch 2101 - loss : 0.39844778180122375\n",
      "Epoch 2201 - loss : 0.3874124586582184\n",
      "Epoch 2301 - loss : 0.37802672386169434\n",
      "Epoch 2401 - loss : 0.9317508339881897\n",
      "Epoch 2501 - loss : 0.3701041638851166\n",
      "Epoch 2601 - loss : 0.36100077629089355\n",
      "Epoch 2701 - loss : 1.2802790403366089\n",
      "Epoch 2801 - loss : 0.46688923239707947\n",
      "Epoch 2901 - loss : 0.34955742955207825\n",
      "Epoch 3001 - loss : 0.3417738974094391\n",
      "Epoch 3101 - loss : 0.3453097641468048\n",
      "Epoch 3201 - loss : 0.6610934734344482\n",
      "Epoch 3301 - loss : 0.35403215885162354\n",
      "Epoch 3401 - loss : 0.33286044001579285\n",
      "Epoch 3501 - loss : 0.3258424401283264\n",
      "Epoch 3601 - loss : 0.32038697600364685\n",
      "Epoch 3701 - loss : 0.4497746527194977\n",
      "Epoch 3801 - loss : 0.3193330466747284\n",
      "Epoch 3901 - loss : 0.3105974495410919\n",
      "Epoch 4001 - loss : 0.3040049076080322\n",
      "Epoch 4101 - loss : 0.4572930335998535\n",
      "Epoch 4201 - loss : 0.30108848214149475\n",
      "Epoch 4301 - loss : 0.33242979645729065\n",
      "Epoch 4401 - loss : 0.33345523476600647\n",
      "Epoch 4501 - loss : 0.31935375928878784\n",
      "Epoch 4601 - loss : 0.29129964113235474\n",
      "Epoch 4701 - loss : 0.28907546401023865\n",
      "Epoch 4801 - loss : 0.2808363139629364\n",
      "Epoch 4901 - loss : 0.4552959203720093\n",
      "Epoch 5001 - loss : 0.2786642014980316\n",
      "Epoch 5101 - loss : 0.2742297351360321\n",
      "Epoch 5201 - loss : 0.34718725085258484\n",
      "Epoch 5301 - loss : 0.8499098420143127\n",
      "Epoch 5401 - loss : 0.28248491883277893\n",
      "Epoch 5501 - loss : 0.27363187074661255\n",
      "Epoch 5601 - loss : 0.26812201738357544\n",
      "Epoch 5701 - loss : 0.26440081000328064\n",
      "Epoch 5801 - loss : 0.26190242171287537\n",
      "Epoch 5901 - loss : 0.26075467467308044\n",
      "Epoch 6001 - loss : 0.2644731104373932\n",
      "Epoch 6101 - loss : 0.34130239486694336\n",
      "Epoch 6201 - loss : 0.3175104260444641\n",
      "Epoch 6301 - loss : 0.3121766448020935\n",
      "Epoch 6401 - loss : 0.35067394375801086\n",
      "Epoch 6501 - loss : 0.3167164623737335\n",
      "Epoch 6601 - loss : 0.35886311531066895\n",
      "Epoch 6701 - loss : 0.2987600862979889\n",
      "Epoch 6801 - loss : 0.2810061573982239\n",
      "Epoch 6901 - loss : 0.3054337799549103\n",
      "Epoch 7001 - loss : 0.26911646127700806\n",
      "Epoch 7101 - loss : 0.27949726581573486\n",
      "Epoch 7201 - loss : 0.3682422935962677\n",
      "Epoch 7301 - loss : 0.27527448534965515\n",
      "Epoch 7401 - loss : 0.3104376494884491\n",
      "Epoch 7501 - loss : 0.2551129162311554\n",
      "Epoch 7601 - loss : 0.2663528323173523\n",
      "Epoch 7701 - loss : 0.2592104971408844\n",
      "Epoch 7801 - loss : 0.26343777775764465\n",
      "Epoch 7901 - loss : 0.2430492639541626\n",
      "Epoch 8001 - loss : 0.24036990106105804\n",
      "Epoch 8101 - loss : 0.24649174511432648\n",
      "Epoch 8201 - loss : 0.24287377297878265\n",
      "Epoch 8301 - loss : 0.2362867146730423\n",
      "Epoch 8401 - loss : 0.240275576710701\n",
      "Epoch 8501 - loss : 0.2389703392982483\n",
      "Epoch 8601 - loss : 0.2317555695772171\n",
      "Epoch 8701 - loss : 0.2277481108903885\n",
      "Epoch 8801 - loss : 0.49267473816871643\n",
      "Epoch 8901 - loss : 0.2314555048942566\n",
      "Epoch 9001 - loss : 0.2269877791404724\n",
      "Epoch 9101 - loss : 0.4238508939743042\n",
      "Epoch 9201 - loss : 0.24944402277469635\n",
      "Epoch 9301 - loss : 0.2262585312128067\n",
      "Epoch 9401 - loss : 0.23544155061244965\n",
      "Epoch 9501 - loss : 0.34925246238708496\n",
      "Epoch 9601 - loss : 0.23166930675506592\n",
      "Epoch 9701 - loss : 0.25701990723609924\n",
      "Epoch 9801 - loss : 0.22082960605621338\n",
      "Epoch 9901 - loss : 0.22273676097393036\n",
      "Epoch 10001 - loss : 0.26297613978385925\n",
      "Epoch 10101 - loss : 0.21449147164821625\n",
      "Epoch 10201 - loss : 0.21958427131175995\n",
      "Epoch 10301 - loss : 0.3246802091598511\n",
      "Epoch 10401 - loss : 0.24278223514556885\n",
      "Epoch 10501 - loss : 0.22160369157791138\n",
      "Epoch 10601 - loss : 0.2549484968185425\n",
      "Epoch 10701 - loss : 0.23797215521335602\n",
      "Epoch 10801 - loss : 0.2164805680513382\n",
      "Epoch 10901 - loss : 0.23991580307483673\n",
      "Epoch 11001 - loss : 0.21546413004398346\n",
      "Epoch 11101 - loss : 0.6443244814872742\n",
      "Epoch 11201 - loss : 0.21086305379867554\n",
      "\n",
      "CONVERGED at epoch 11249 - loss : 0.1997154802083969\n",
      "total training time (sec): 7.91778302192688\n"
     ]
    }
   ],
   "source": [
    "cost = train(epochs=int(1e5), epsilon=0.2) #hopefully, it didn't overfit. :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph cost\n",
    "plt.plot(cost)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Cost over epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, verification, pprint=False):\n",
    "    \"\"\"Based on X_test or X_train, predict overall model accuracy.\"\"\"\n",
    "    predictions=[]\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data):\n",
    "            y_pred = model(data)\n",
    "            predictions.append(y_pred.argmax().item())\n",
    "\n",
    "    predictions = np.array(predictions, dtype=np.int8)\n",
    "    loan = np.where(predictions == 1)[0]\n",
    "    not_loan = np.where(predictions == 0)[0]\n",
    "    \n",
    "    if(pprint): #print logs and graph\n",
    "        print(f\"Prediction loans count: {len(loan)}\")\n",
    "        print(f\"Prediction not loans count: {len(not_loan)}\")\n",
    "        plt.hist(loan, label='Loan')\n",
    "        plt.hist(not_loan, label='Not Loan')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Observation\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(\"Histogram of loan vs. not loan observations\")\n",
    "        plt.show()\n",
    "    score = accuracy_score(verification, predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.917\n",
      "Test set accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set accuracy:\", np.round(accuracy(X_train, y_train), 3)) #92% accuracy on test set.\n",
    "print(\"Test set accuracy:\", np.round(accuracy(X_test, y_test), 3))    #75% accuracy on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read more: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(model.state_dict(), \"../models/loan_prediction.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Steps for conformal prediction:\n",
    "<ol>\n",
    "    <li>Calculate nonconformal score using Nearest Centroid algorithm</li>\n",
    "    <li>Calculate p-values corresponding to the current possible prediction/label</li>\n",
    "    <li>Output j as predicted label of the current example with p-value $p_j$ if and only if $p_j > \\epsilon $ </li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Centroid algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid(point, centroid):\n",
    "    \"\"\"Calculate the distance between a test point and a centroid point\"\"\"\n",
    "    #assuming point and centroid are tensors\n",
    "    point = np.array(point.tolist())\n",
    "    centroid = np.array(centroid.tolist())\n",
    "    return np.linalg.norm(point - centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(data):\n",
    "    \"\"\"Find the centroid for one class of object\"\"\"\n",
    "    features, observations = data.shape\n",
    "    if(features > observations):\n",
    "        raise ValueError(\"too few observations\")\n",
    "    \n",
    "    central = []\n",
    "    for i in range(features):\n",
    "        mean = torch.mean(data[i])\n",
    "        central.append(mean)\n",
    "    return torch.FloatTensor(central).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_classes(data, labels):\n",
    "    \"\"\"Split data into 2 classes based on corresponding label\"\"\"\n",
    "    loan, not_loan = [], []\n",
    "    for i in range(data.shape[0]):\n",
    "        if(labels[i].item() == 0):#no loan\n",
    "            not_loan.append(data[i].tolist())\n",
    "        else:\n",
    "            loan.append(data[i].tolist())\n",
    "    loan = torch.tensor(loan).to(device)        \n",
    "    not_loan = torch.tensor(not_loan).to(device)\n",
    "    return loan, not_loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_train, not_loan_train = split_classes(X_train, y_train)\n",
    "loan_test, not_loan_test = split_classes(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_centroid, not_loan_centroid = centroid(loan_train.T), centroid(not_loan_train.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non conformity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonconformity_measure(test_point, label, loan_centroid, non_loan_centroid):\n",
    "    \"\"\"Computes the nonconformity score for a single test-point (HELPER method)\"\"\"\n",
    "    loan_dist = euclid(test_point, loan_centroid)\n",
    "    no_loan_dist = euclid(test_point, non_loan_centroid)\n",
    "    if(label == 1):#loan\n",
    "        return loan_dist/no_loan_dist\n",
    "    else:\n",
    "        return no_loan_dist/loan_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_nc(testing_data, centroids):\n",
    "    \"\"\"Calculate the non-conformity measure for a subset of data\"\"\"\n",
    "    nums = len(testing_data) #number of conformity scores\n",
    "    l_c, nl_c = centroids #extract centroid into loan and not loan centroid\n",
    "    y_pred = model(testing_data)\n",
    "    predictions = [x.argmax().item() for x in y_pred]\n",
    "    non_conformity_scores = [nonconformity_measure(testing_data[i], predictions[i], l_c, nl_c) for i in range(nums)]\n",
    "    return torch.FloatTensor(non_conformity_scores).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_value(data, labels, centroid, nc_scores):\n",
    "    \"\"\"Calculate p-value from a distribution on non-conformity scores\"\"\"\n",
    "    #compute the conformity scores of dataset first (this will be the training data)\n",
    "    #after this, use the conformal function to determine p-value: #{j = 1,...,n: alpha_j  alpha_n}/N\n",
    "    N = len(labels)\n",
    "    lc, nlc = centroid\n",
    "    non_conformity_scores = [nonconformity_measure(data[i], labels[i], lc, nlc) for i in range(N)]\n",
    "    output = []\n",
    "    for test_nc in nc_scores:\n",
    "        scores = 0\n",
    "        for j in range(len(non_conformity_scores)):\n",
    "            if(non_conformity_scores[j] >= test_nc):\n",
    "                scores += 1\n",
    "\n",
    "        p_value = scores/N\n",
    "        output.append(p_value)\n",
    "        \n",
    "    return torch.FloatTensor(output).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_scores = subset_nc(X_test, (loan_centroid, not_loan_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = compute_p_value(X_train, y_train, (loan_centroid, not_loan_centroid), nc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence: 0.078125; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.2395833134651184; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.09375; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.6354166269302368; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.4479166865348816; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.5078125; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.8020833134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.7161458730697632; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.5677083730697632; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.2083333134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.8489583134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.4322916865348816; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.71875; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.375; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.3854166865348816; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.8723958134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2447916865348816; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.8776041865348816; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.6666666269302368; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.1927083134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.05208331346511841; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.3020833134651184; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.3645833134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.6067708730697632; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.3645833134651184; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.5182291269302368; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.5546875; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.15625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.08072918653488159; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.5182291269302368; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.0078125; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.5390625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.15625; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.10677081346511841; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.65625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.6848958730697632; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.7057291269302368; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.6276041269302368; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.7552083134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.4322916865348816; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.6953125; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.1432291865348816; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.05208331346511841; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.7369791269302368; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.9010416865348816; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.34375; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.0546875; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.078125; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.796875; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.375; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.640625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2604166865348816; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.4348958134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2578125; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.0546875; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.65625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.010416686534881592; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.46875; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.2395833134651184; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.4296875; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.7083333730697632; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.8776041865348816; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2630208134651184; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.6145833730697632; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2708333134651184; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.4583333134651184; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.3854166865348816; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.7395833730697632; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.640625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.5572916269302368; Actual label: 1; Predicted label: 0\n",
      "Confidence: 0.5182291269302368; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.15625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.5442708730697632; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.9010416865348816; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.8151041865348816; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.6276041269302368; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.8776041865348816; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.875; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.3854166865348816; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.8333333134651184; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.6796875; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.8515625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.875; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2135416865348816; Actual label: 0; Predicted label: 0\n",
      "Confidence: 0.3984375; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.2708333134651184; Actual label: 0; Predicted label: 1\n",
      "Confidence: 0.3020833134651184; Actual label: 0; Predicted label: 0\n",
      "Confidence: 1.0; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.65625; Actual label: 1; Predicted label: 1\n",
      "Confidence: 0.8854166865348816; Actual label: 0; Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "n = 90\n",
    "for i in range(n):\n",
    "    print(f\"Confidence: {1-p_values[i]}; Actual label: {y_test[i]}; Predicted label: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test)\n",
    "predictions = [x.argmax().item() for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "for a, b in zip(predictions, y_test):\n",
    "    if(a == b):\n",
    "        score += 1/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499999999999994"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
